---
title: "Simulation"
author: "Zirui Zhang"
date: "2025-01-10"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(rje)
library(caret)
library(ks)
library(kernlab)
```

# data generation

## S, Y 
```{r}
# S0
ES0 <- function(X) {
  X1 <- X[, 1]
  X2 <- X[, 2]
  X3 <- X[, 3]

  # ES0_1 = -2*sin(X1) + 0.5*X3
  # ES0_2 = X2 + X1
  ES0_1 = -2*X1
  ES0_2 = X2
  
  
  ES0 <- cbind(ES0_1, ES0_2)
  ES0
}

# S1
ES1 <- function(X) {
  X1 <- X[, 1]
  X2 <- X[, 2]
  X3 <- X[, 3]
  
  #ES1_1 = sin(X1) + X3
  #ES1_2 = -2*X2 - X1
  ES1_1 = X1
  ES1_2 = -2*X2
  
  ES1 <- cbind(ES1_1, ES1_2)
  ES1
}

# Y0
EY0 <- function(X, S0) {
  #beta_s0 <- c(1, -2)
  beta_s0 <- c(1, -1)
  EY0 <- S0 %*% beta_s0 # + X[,1]*X[, 3] + 2*X[,1]^2
  EY0
}

# Y1
EY1 <- function(X, S1) {
  #beta_s1 <- c(0.5, -0.5)
  beta_s1 <- c(1, -1)
  EY1 <- S1 %*% beta_s1 + 0.2*X[, 3] # + X[,2]*X[, 3] + X[,1]*X[, 2] + X[,1]^2 + 5*X[, 3]
  EY1
}

# error generator
err <- function(n, d, var) { # n dp, d dimension, variance
  err_matrix <- matrix(rnorm(n * d, mean = 0, sd = sqrt(var)), nrow = n, ncol = d)
  return(err_matrix)
}
```

## GD function
```{r}
DP <- list()
GD <- function(n){
  
  l = 2 #?# use Try() to ensure data generates enough
  Xa <- data.frame(X1 = rnorm(l*2*n, 0, 0.5),
                   X2 = rnorm(l*2*n, 0, 1),
                   X3 = runif(l*2*n, min = -1, max = 1)) |> 
    mutate(p1 = expit(X1 + X2 + X3)) # almost symmetric around 0
  Xa$t <- rbinom(n = length(Xa$p1), size = 1, prob = Xa$p1)
  
  X <- Xa |> filter(t == 0) |> slice(1:n) |> select(X1, X2, X3) |> as.matrix()
  Xt <- Xa |> filter(t == 1) |> slice(1:n) |> select(X1, X2, X3) |> as.matrix()
  
  
  #S: n x 3 matrix
  e_S0 <- err(n, 2, 0.5) # d=2, var=0.5
  e_S1 <- err(n, 2, 0.5)
  S0 <- ES0(X) + e_S0
  S1 <- ES1(X) + e_S1
  
  #Y: n x 1 matrix
  e_Y0 <- err(n, 1, 0.5)
  e_Y1 <- err(n, 1, 0.5)
  Y0 <- EY0(X, S0) + e_Y0
  Y1 <- EY1(X, S1) + e_Y1
  
  #A: n x 1 matrix
  A <- c(rep(0, n/2), rep(1, n/2)) # first half: A=0, second half: A=1 # for better sample split
  
  
  # X <- as.data.frame(X)
  # Xt <- as.data.frame(Xt)
  DP <- list('A'=A, 'X'=X, 'Xt'=Xt, 'Y0'=Y0,'Y1'=Y1, 'S0'=S0, 'S1'=S1)
  return(DP)
}
```

# Algorithm
## Sample split function
```{r}
Split2 <- function(K, input) {
  I1 <- rep(0, input)        # initiate the fold labels storage for each data point
  half <- input / 2
  
  # random permutation of [1~half]
  firstHalfIDs <- sample(1:half, half, replace = FALSE)
  
  # number of points per fold in the first half
  m <- half / K
  
  # assign folds to the first half
  for (i in 1:K) {
    # The slice for fold i
    theseIDs <- firstHalfIDs[((i - 1) * m + 1) : (i * m)]
    I1[theseIDs] <- i
  }
  
  # random permutation of [half+1~input]
  secondHalfIDs <- sample((half + 1) : input, half, replace = FALSE)
  
  # assign folds to the second half
  for (i in 1:K) {
    theseIDs <- secondHalfIDs[((i - 1) * m + 1) : (i * m)]
    I1[theseIDs] <- i
  }
  
  return(I1)
}
```


## Bootstrap functionS
### resample
```{r}
resample_data <- function(Outt, Targett) {

  n_out   <- length(Outt$delta_Y) 
  n_targ  <- length(Targett$delta_Yt) 

  # draw indices with replacement
  idx_out  <- sample(seq_len(n_out),  n_out,  replace=TRUE)
  idx_targ <- sample(seq_len(n_targ), n_targ, replace=TRUE)

  # new bootstrap Out list
  Out_boot <- list(
    delta_Y = Outt$delta_Y[idx_out],
    Y1new   = Outt$Y1new[idx_out],
    m1_pred = Outt$m1_pred[idx_out],
    Y0new   = Outt$Y0new[idx_out],
    m0_pred = Outt$m0_pred[idx_out],
    Anew    = Outt$Anew[idx_out],
    # S, matrices:
    delta_S = Outt$delta_S[idx_out, , drop=FALSE],
    S1new   = Outt$S1new[idx_out, , drop=FALSE],
    r1_pred = Outt$r1_pred[idx_out, , drop=FALSE],
    S0new   = Outt$S0new[idx_out, , drop=FALSE],
    r0_pred = Outt$r0_pred[idx_out, , drop=FALSE],
    # omega:
    omega   = Outt$omega[idx_out])
  

  # new bootstrap Target list
  Target_boot <- list(
    delta_Yt = Targett$delta_Yt[idx_targ],
    delta_St = Targett$delta_St[idx_targ, , drop=FALSE]
  )

  # return
  list(Out_boot=Out_boot, Target_boot=Target_boot)
}
```

## outcome calculation
```{r, PQ}
calculation_pq <- function(NuisanceFit, TargetFit, gamma) {
  
  Xnew=NuisanceFit$Xnew
  Anew=NuisanceFit$Anew
  omega=NuisanceFit$omega
  Y0new=NuisanceFit$Y0new
  Y1new=NuisanceFit$Y1new
  S0new=NuisanceFit$S0new
  S1new=NuisanceFit$S1new
  m0_pred=NuisanceFit$m0_pred
  m1_pred=NuisanceFit$m1_pred
  r0_pred=NuisanceFit$r0_pred
  r1_pred=NuisanceFit$r1_pred
  b0_pred=NuisanceFit$b0_pred
  b1_pred=NuisanceFit$b1_pred
  c0_pred=NuisanceFit$c0_pred
  c1_pred=NuisanceFit$c1_pred
  d0_pred=NuisanceFit$d0_pred
  d1_pred=NuisanceFit$d1_pred
  alpha_k = cbind(X0 = 1, Xnew) %*% gamma
  
  Xt = TargetFit$Xt
  m0_t=TargetFit$m0_t
  m1_t=TargetFit$m1_t
  r0_t=TargetFit$r0_t
  r1_t=TargetFit$r1_t
  b0_t=TargetFit$b0_t
  b1_t=TargetFit$b1_t
  c0_t=TargetFit$c0_t
  c1_t=TargetFit$c1_t
  d0_t=TargetFit$d0_t
  d1_t=TargetFit$d1_t
  alpha_t = cbind(X0 = 1, Xt) %*% gamma
  
  dims <- ncol(TargetFit$r0_t)
  
    # unconditional debiased:
  D0 <- matrix(colMeans(d0_t), nrow = dims, ncol = dims) + # target # D0, D1: stored as p*p matrix; other nuisance as numeric
    matrix(colMeans(((t(apply(S0new, 1, function(v) as.vector(outer(v,v)))) - d0_pred)*omega)[Anew == 0,,drop = FALSE]),
           nrow = dims, ncol = dims) # source k-th fold
  D1 <- matrix(colMeans(d1_t), nrow = dims, ncol = dims) +
    matrix(colMeans(((t(apply(S1new, 1, function(v) as.vector(outer(v,v)))) - d1_pred)*omega)[Anew == 1,,drop = FALSE]),
           nrow = dims, ncol = dims)
  R0 <- colMeans(r0_t) +
    colMeans(((S0new - r0_pred)*omega)[Anew == 0,,drop = FALSE])
  R1 <- colMeans(r1_t) +
    colMeans(((S1new - r1_pred)*omega)[Anew == 1,,drop = FALSE])
  C0 <- colMeans(c0_t) +
    colMeans(((S0new*as.vector(Y0new) - c0_pred)*omega)[Anew == 0,,drop = FALSE])
  C1 <- colMeans(c1_t) +
    colMeans(((S1new*as.vector(Y1new) - c1_pred)*omega)[Anew == 1,,drop = FALSE])
  M0 <- mean(m0_t) + mean(((Y0new - m0_pred)*omega)[Anew == 0,drop = FALSE])
  M1 <- mean(m1_t) + mean(((Y1new - m1_pred)*omega)[Anew == 1,drop = FALSE])
  B0 <- mean(b0_t) + mean((((Y0new)^2-b0_pred)*omega)[Anew == 0,drop = FALSE])
  B1 <- mean(b1_t) + mean((((Y1new)^2-b1_pred)*omega)[Anew == 1,drop = FALSE])
  
  # conditional debiased:
  ad1_target <- as.vector(alpha_t)*d1_t
  ad1_source <- (as.vector(alpha_k)*omega*(t(apply(S1new, 1, function(v) as.vector(outer(v,v)))) - d1_pred))
  ad0_target <- as.vector(1/alpha_t)*d0_t
  ad0_source <- (as.vector(1/alpha_k)*omega*(t(apply(S0new, 1, function(v) as.vector(outer(v,v)))) - d0_pred))
  
  ar1sq_target <- as.vector(alpha_t)*t(apply(r1_t, 1, function(s) as.vector(outer(s,s))))
  ar1sq_source <- as.vector(alpha_k)*omega*(
    t(sapply(seq_len(nrow(S1new)), function(i) {as.vector(outer(S1new[i, ]-r1_pred[i, ], r1_pred[i, ]))})) +
      t(sapply(seq_len(nrow(S1new)), function(i) {as.vector(outer(r1_pred[i, ], S1new[i, ]-r1_pred[i, ]))})))
  ar0sq_target <- as.vector(1/alpha_t)*t(apply(r0_t, 1, function(s) as.vector(outer(s,s))))
  ar0sq_source <- as.vector(1/alpha_k)*omega*(
    t(sapply(seq_len(nrow(S0new)), function(i) {as.vector(outer(S0new[i, ]-r0_pred[i, ], r0_pred[i, ]))})) +
      t(sapply(seq_len(nrow(S0new)), function(i) {as.vector(outer(r0_pred[i, ], S0new[i, ]-r0_pred[i, ]))})))
  
  r1r0_target <- t(sapply(seq_len(nrow(r1_t)), function(i) {as.vector(outer(r1_t[i, ], r0_t[i, ]))}))
  r1r0_source <- colMeans((omega*t(sapply(seq_len(nrow(S1new)), function(i)
  {as.vector(outer((S1new-r1_pred)[i,], r0_pred[i,]))})))[Anew == 1,,drop = FALSE]) + 
    colMeans((omega*t(sapply(seq_len(nrow(S0new)), function(i) 
    {as.vector(outer(r1_pred[i,], (S0new-r0_pred)[i,]))})))[Anew == 0,,drop = FALSE])
  r0r1_target <- t(sapply(seq_len(nrow(r0_t)), function(i) {as.vector(outer(r0_t[i, ], r1_t[i, ]))}))
  r0r1_source <- colMeans((omega*t(sapply(seq_len(nrow(S0new)), function(i)
  {as.vector(outer((S0new-r0_pred)[i,], r1_pred[i,]))})))[Anew == 0,,drop = FALSE]) + 
    colMeans((omega*t(sapply(seq_len(nrow(S1new)), function(i) 
    {as.vector(outer(r0_pred[i,], (S1new-r1_pred)[i,]))})))[Anew == 1,,drop = FALSE])
  
  ac1_target <- as.vector(alpha_t)*c1_t
  ac1_source <- (as.vector(alpha_k)*omega*(S1new*as.vector(Y1new)-c1_pred))
  ac0_target <- as.vector(1/alpha_t)*c0_t
  ac0_source <- as.vector(1/alpha_k)*omega*(S0new*as.vector(Y0new)-c0_pred)
  
  am1r1_target <- as.vector(alpha_t)*r1_t*as.vector(m1_t)
  am1r1_source <- as.vector(alpha_k)*omega*(r1_pred*as.vector(Y1new-m1_pred) + (S1new-r1_pred)*as.vector(m1_pred))
  am0r0_target <- as.vector(1/alpha_t)*r0_t*as.vector(m0_t)
  am0r0_source <- as.vector(1/alpha_k)*omega*(r0_pred*as.vector(Y0new-m0_pred) + (S0new-r0_pred)*as.vector(m0_pred))
  
  m1r0_target <- r0_t*as.vector(m1_t)
  m1r0_source <- colMeans((omega*r0_pred*as.vector(Y1new-m1_pred))[Anew == 1,,drop = FALSE]) + colMeans((omega*(S0new-r0_pred)*as.vector(m1_pred))[Anew == 0,,drop = FALSE])
  m0r1_target <- r1_t*as.vector(m0_t)
  m0r1_source <- colMeans((omega*r1_pred*as.vector(Y0new-m0_pred))[Anew == 0,,drop = FALSE]) + colMeans((omega*(S1new-r1_pred)*as.vector(m0_pred))[Anew == 1,,drop = FALSE])
  
  m1m0_target <- m1_t*m0_t
  m1m0_source <- mean((omega*(Y1new-m1_pred)*m0_pred)[Anew == 1,,drop = FALSE]) + mean((omega*(Y0new-m0_pred)*m1_pred)[Anew == 0,,drop = FALSE])
  
  ab1_target <- alpha_t*b1_t
  ab1_source <- (alpha_k*omega*(Y1new^2-b1_pred))
  ab0_target <- (1/alpha_t)*b0_t
  ab0_source <- ((1/alpha_k)*omega*(Y0new^2-b0_pred))
  
  am1sq_target <- alpha_t*m1_t^2
  am1sq_source <- (alpha_k*omega*(Y1new-m1_pred)*m1_pred)
  am0sq_target <- (1/alpha_t)*m0_t^2
  am0sq_source <- ((1/alpha_k)*omega*(Y0new-m0_pred)*m0_pred)
  
  # P hat:
  P <- D1 - outer(R1, R1) + D0 - outer(R0, R0) + outer(R1, R0) + outer(R0, R1) + # unconditional
    # + a*d1:
    matrix(colMeans(ad1_target) + colMeans(ad1_source[Anew == 1,,drop = FALSE]),
      nrow = dims, ncol = dims
    ) +
    # + 1/a*d0:
    matrix(colMeans(ad0_target) + colMeans(ad0_source[Anew == 0,,drop = FALSE]),
      nrow = dims, ncol = dims
    ) -
    # - a*r1r1:
    matrix(colMeans(ar1sq_target) + colMeans(ar1sq_source[Anew == 1,,drop = FALSE]),
      nrow = dims, ncol = dims
    ) -
    # - 1/a*r0r0:
    matrix(colMeans(ar0sq_target) + colMeans(ar0sq_source[Anew == 0,,drop = FALSE]),
      nrow = dims, ncol = dims
    ) -
    # -r1r0
    matrix(colMeans(r1r0_target) + r1r0_source,
      nrow = dims, ncol = dims
    ) -
    # -r0r1
    matrix(colMeans(r0r1_target) + r0r1_source,
      nrow = dims, ncol = dims
    )
  
  # Q hat (calculated as t(Q)):
  QT <- C1 - M1*R1 + C0 - M0*R0 + M1*R0 + M0*R1 +
    # + a*c1
    colMeans(ac1_target) + colMeans(ac1_source[Anew == 1,,drop = FALSE]) +
    # + 1/a*c0
    colMeans(ac0_target) + colMeans(ac0_source[Anew == 0,,drop = FALSE]) -
    # - a*m1r1
    (colMeans(am1r1_target) + colMeans(am1r1_source[Anew == 1,,drop = FALSE])
    ) -
    # -1/a*m0r0
    (colMeans(am0r0_target) + colMeans(am0r0_source[Anew == 0,,drop = FALSE])
    ) +
    # m1r0
    colMeans(m1r0_target) + m1r0_source
     +
    # m0r1
    colMeans(m0r1_target) + m0r1_source
  
  Q <- t(t(QT))
  
  # solve(P) %*% Q

  # Return them
  list(P = P, Q = Q)
}
```

## Estimation function
```{r}
estimate <- function(In, Out, Target, givenestimator, NBoot) {
  
  # In and Out both from source data, defined through sample splitting
  
  # In: for training model  #(1-1/K)*n dp
  X <- In$X
  S0 <- In$S0
  S1 <- In$S1
  Y0 <- In$Y0
  Y1 <- In$Y1
  A <- In$A
  # new added for CS bound:
  b0 <- Y0^2 # keeping both A=0/1 now but separating when doing regression
  b1 <- Y1^2
  c0 <- S0*as.vector(Y0)
  c1 <- S1*as.vector(Y1)
  d0 <- t(apply(S0, 1, function(v) as.vector(v %o% v))) # 1*(p^2)
  d1 <- t(apply(S1, 1, function(v) as.vector(v %o% v))) 
  
  # Out: for estimation  #(1/K)*n dp
  Xnew <- Out$X
  S0new <- Out$S0
  S1new <- Out$S1
  Y0new <- Out$Y0
  Y1new <- Out$Y1
  Anew <- Out$A
  
  # Target: X from target population, for theta estimation   # n dp
  Xt <- Target
  
  ######################## omega estimate ########################
  Xc <- data.frame(rbind(cbind(X, source = 0), cbind(Xt, source = 1))) # pT = p1
  
  #### 1. glm:
  Xc$source <- as.factor(Xc$source)
  p <- glm(source ~ ., data = Xc, family = binomial) # logistic regression
  p1 <- predict(p, newdata = data.frame(Xnew), type = "response")
  omega <- (p1/(1-p1))*(1-1/K)
  
  fit_model <- function(outcome, predictor) {
    train(outcome ~ ., data = data.frame(outcome, predictor),
          method = 'glm',
          trControl = trainControl(method = "cv", number = 5, verboseIter = FALSE)
          )
  }
  
  ##### 2. machine learning:
  #Xc$source <- factor(Xc$source, 
  #                  levels = c(0,1), 
  #                  labels = c("Class0", "Class1"))
  #
  #fitControl_p <- trainControl( # for p
  #    method = "cv",
  #    number = 5,
  #    verboseIter=FALSE,
  #    classProbs  = TRUE) # for classification
  #
  #fitControl <- trainControl( # for nuisance models
  #    method = "cv",
  #    number = 5,
  #    verboseIter=FALSE)
  #
  ## nuisance:
  #fit_model <- function(outcome, predictor) {
  #  train(outcome ~ ., data = data.frame(outcome, predictor),
  #        method = givenestimator,
  #        trControl = fitControl,
  #        verbose = FALSE
  #  )}
  #
  ## p & omega, for different algrthms:
  #if(givenestimator %in% c('svmLinear', 'svmLinear2')){
  #  
  #  p <- train(source ~., data = Xc, 
  #             method = givenestimator, 
  #             trControl =fitControl_p,
  #             verbose = FALSE,
  #             probability = TRUE) # unique to svmLinear2
  #  
  #}else{
  #  
  #  p <- train(source ~., data = Xc, 
  #             method = givenestimator, 
  #             trControl =fitControl_p,
  #             verbose = FALSE) # c('gbm','rf','nnet')
  #  
  #}
  #
  #p1 <- predict(p, newdata = data.frame(Xnew), type = "prob")$Class1
  #omega <- (p1/(1-p1))*(1-1/K)

  #initialize model-storing list for high-d S (p*1), c (p*1), and d (p*p)
  dims <- ncol(S0)
  dims2 <- dims^2
  
  # Separate data by A=0/1 for training purpose
  X_A0 <- X[A == 0, , drop = FALSE]
  X_A1 <- X[A == 1, , drop = FALSE]
  S0_train <- S0[A == 0, , drop = FALSE]
  S1_train <- S1[A == 1, , drop = FALSE]
  Y0_train <- Y0[A == 0, , drop = FALSE]
  Y1_train <- Y1[A == 1, , drop = FALSE]
  # new added for CS bound:
  b0_train <- b0[A == 0, , drop = FALSE]
  b1_train <- b1[A == 1, , drop = FALSE]
  c0_train <- c0[A == 0, , drop = FALSE]
  c1_train <- c1[A == 1, , drop = FALSE]
  d0_train <- d0[A == 0, , drop = FALSE]
  d1_train <- d1[A == 1, , drop = FALSE]
  
  # creat list for n-d estimators
  modelS0 <- list()
  modelS1 <- list()
  modelc0 <- list()
  modelc1 <- list()
  modeld0 <- vector("list", dims2)
  modeld1 <- vector("list", dims2)
  
  # Regression:
  fitY0 <- fit_model(Y0_train, X_A0) # Y0 ~ X_{A=0}
  fitY1 <- fit_model(Y1_train, X_A1) # Y1 ~ X_{A=1}
  fitb0 <- fit_model(b0_train, X_A0)
  fitb1 <- fit_model(b1_train, X_A1)
  
  for (i in seq_len(dims)) { # p
    
    S0_dim <- S0_train[, i]
    S1_dim <- S1_train[, i]
    c0_dim <- c0_train[, i]
    c1_dim <- c1_train[, i]
    
    modelS0[[i]] <- fit_model(S0_dim, X_A0)
    modelS1[[i]] <- fit_model(S1_dim, X_A1) # store models for S_i
    modelc0[[i]] <- fit_model(c0_dim, X_A0)
    modelc1[[i]] <- fit_model(c1_dim, X_A1) 

  }
  
  for (j in seq_len(dims2)) { # p^2
    
  d0_dim <- d0_train[, j]
  d1_dim <- d1_train[, j]
  
  modeld0[[j]] <- fit_model(d0_dim, X_A0)
  modeld1[[j]] <- fit_model(d1_dim, X_A1)
  
  }
  # Regression ends #
  
  # New Regression:
  # (train nuisance_error)
  
  # format outcome (using source[-k] data), regardless of A = 0/1
  b0_e <- (Y0 - predict(fitY0, newdata = X))^2 # true Y(a) - m(a) # mse/var = 0.3
  b1_e <- (Y1 - predict(fitY1, newdata = X))^2
  c0_e <- as.vector(Y0 - predict(fitY0, newdata = X))*(S0 - sapply(modelS0, predict, newdata = X))
  c1_e <- as.vector(Y1 - predict(fitY1, newdata = X))*(S1 - sapply(modelS1, predict, newdata = X))
  d0_e <- t(apply((S0 - sapply(modelS0, predict, newdata = X)), 1, function(v) as.vector(v %o% v))) # mse/var = 0.3
  d1_e <- t(apply((S1 - sapply(modelS1, predict, newdata = X)), 1, function(v) as.vector(v %o% v)))
  
  b0_e_train <- b0_e[A == 0, , drop = FALSE]
  b1_e_train <- b1_e[A == 1, , drop = FALSE]
  c0_e_train <- c0_e[A == 0, , drop = FALSE]
  c1_e_train <- c1_e[A == 1, , drop = FALSE]
  d0_e_train <- d0_e[A == 0, , drop = FALSE]
  d1_e_train <- d1_e[A == 1, , drop = FALSE]
  
  # dim = 1
  fitb0_e <- fit_model(b0_e_train, X_A0)
  fitb1_e <- fit_model(b1_e_train, X_A1)
  
  # dim = p
  modelc0_e <- list()
  modelc1_e <- list()
  modeld0_e <- vector("list", dims2)
  modeld1_e <- vector("list", dims2)

  for (i in seq_len(dims)) {

    c0_dim <- c0_e_train[, i]
    c1_dim <- c1_e_train[, i]
    
    modelc0_e[[i]] <- fit_model(c0_dim, X_A0)
    modelc1_e[[i]] <- fit_model(c1_dim, X_A1)

  }
  
  for (j in seq_len(dims2)) { # p^2
    
  d0_dim <- d0_e_train[, j]
  d1_dim <- d1_e_train[, j]
  
  modeld0_e[[j]] <- fit_model(d0_dim, X_A0)
  modeld1_e[[j]] <- fit_model(d1_dim, X_A1)
  
  }
  # New Regression ends #
  
  # NUISANCE: Prediction for Source k-th X (regardless of A)
  m0_pred <- predict(fitY0, newdata = Xnew)
  m1_pred <- predict(fitY1, newdata = Xnew)
  b0_pred <- predict(fitb0, newdata = Xnew)
  b1_pred <- predict(fitb1, newdata = Xnew)
  r0_pred <- sapply(modelS0, predict, newdata = Xnew)
  r1_pred <- sapply(modelS1, predict, newdata = Xnew)
  c0_pred <- sapply(modelc0, predict, newdata = Xnew)
  c1_pred <- sapply(modelc1, predict, newdata = Xnew)
  d0_pred <- sapply(modeld0, predict, newdata = Xnew)
  d1_pred <- sapply(modeld1, predict, newdata = Xnew)
  
  # NUISANCE: Prediction for Target X (A unknown)
  # m,r,c,d
  m0_t <- predict(fitY0, newdata = Xt)
  m1_t <- predict(fitY1, newdata = Xt)
  b0_t <- predict(fitb0, newdata = Xt) # not used in numerator
  b1_t <- predict(fitb1, newdata = Xt) # not used in numerator
  r0_t <- sapply(modelS0, predict, newdata = Xt)
  r1_t <- sapply(modelS1, predict, newdata = Xt)
  c0_t <- sapply(modelc0, predict, newdata = Xt)
  c1_t <- sapply(modelc1, predict, newdata = Xt)
  d0_t <- sapply(modeld0, predict, newdata = Xt)
  d1_t <- sapply(modeld1, predict, newdata = Xt)
  
  #  NUISANCE_ERROR: Prediction for Source k-th X (regardless of A)
  b0_pred_e <- predict(fitb0_e, newdata = Xnew)
  b1_pred_e <- predict(fitb1_e, newdata = Xnew)
  c0_pred_e <- sapply(modelc0_e, predict, newdata = Xnew)
  c1_pred_e <- sapply(modelc1_e, predict, newdata = Xnew)
  d0_pred_e <- sapply(modeld0_e, predict, newdata = Xnew)
  d1_pred_e <- sapply(modeld1_e, predict, newdata = Xnew)
  
  #  NUISANCE_ERROR: Prediction for Target X
  b0_t_e <- predict(fitb0_e, newdata = Xt)
  b1_t_e <- predict(fitb1_e, newdata = Xt)
  c0_t_e <- sapply(modelc0_e, predict, newdata = Xt)
  c1_t_e <- sapply(modelc1_e, predict, newdata = Xt)
  d0_t_e <- sapply(modeld0_e, predict, newdata = Xt)
  d1_t_e <- sapply(modeld1_e, predict, newdata = Xt)
  
  # Prepare data list with nuisance estimators for beta & V calculation
  NuisanceFit <- list(
    Xnew=Xnew,
    Anew=Anew,
    omega=omega,
    Y0new=Y0new, Y1new=Y1new, S0new=S0new, S1new=S1new, 
    m0_pred=m0_pred, m1_pred=m1_pred,
    r0_pred=r0_pred, r1_pred=r1_pred,
    b0_pred=b0_pred, b1_pred=b1_pred,
    c0_pred=c0_pred, c1_pred=c1_pred,
    d0_pred=d0_pred, d1_pred=d1_pred,
    # error terms:
    b0_pred_e=b0_pred_e,b1_pred_e=b1_pred_e,
    c0_pred_e=c0_pred_e,c1_pred_e=c1_pred_e,
    d0_pred_e=d0_pred_e,d1_pred_e=d1_pred_e
    )
  
  TargetFit <- list(
    Xt = Xt,
    m0_t=m0_t, m1_t=m1_t, 
    r0_t=r0_t, r1_t=r1_t,
    b0_t=b0_t, b1_t=b1_t,
    c0_t=c0_t, c1_t=c1_t,
    d0_t=d0_t, d1_t=d1_t,
    # error terms:
    b0_t_e=b0_t_e, b1_t_e=b1_t_e,
    c0_t_e=c0_t_e, c1_t_e=c1_t_e,
    d0_t_e=d0_t_e, d1_t_e=d1_t_e
    )
  
  ## Compute the point estimate:
  #nuisance_fit <- calculation_pq(Outt, Targett)
  #P_hat <- nuisance_fit$P
  #Q_hat <- nuisance_fit$Q

  ## Bootstrap estimates:
  #B_boo <- matrix(NA, nrow = dims, ncol = NBoot)          # each col is B_{r}
  #C_boo <- array(NA, dim = c(dims, dims, NBoot))          # each slice is C_{r}
  #D_boo <- numeric(NBoot)
  #
  #for (b in seq_len(NBoot)) { # index b for bootstrapping
  #  # 1. re-sample
  #  boot_data <- resample_data(Outt, Targett)
  #  Out_boot    <- boot_data$Out_boot
  #  Target_boot <- boot_data$Target_boot
  #  
  #  # 2. calculation
  #  fit_boo <- calculation_pq(Out_boot, Target_boot)
  #  B_boo[,b]  <- fit_boo$B
  #  C_boo[,,b] <- fit_boo$C
  #  D_boo[b]   <- fit_boo$D
  #  
  #}
  

  list(
   NuisanceFit = NuisanceFit,
   TargetFit = TargetFit
  )
  
}
```

# Simulation
```{r}
sim_function <- function(N, n, K, givenestimator, NBoot) {

  # theta_hat_list <- list()
  # tau_hat_list <- list()
  # se_theta_list <- list()
  # se_tau_list   <- list()
  # theta_ci_lower_list <- list()
  # theta_ci_upper_list <- list()
  # tau_ci_lower_list   <- list()
  # tau_ci_upper_list   <- list()
  
  for (i in 1:N) {
    
    DP <- GD(n) 
    Index <- Split2(K, n) # sample split
    dimS <- ncol(DP$S0) # dim(theta) = dim(S)
    dimX <- 3
    gamma0 <- matrix(1e-6, dimX+1, 1) # gamma = (000) would case error

    # array for storing B, C, D from the K folds
    NuisanceFit_folds <- vector("list", K)
    TargetFit_folds   <- vector("list", K)
    P_hat_folds <- array(NA, dim = c(dimS, dimS, K))
    Q_hat_folds <- matrix(NA, nrow=dimS, ncol=K)
    V <- numeric(K)
    gamma_i <- matrix(NA, nrow=dimS, ncol=K)
    ha_folds <- array(NA, dim = c(dimX+1, dimX+1, K))
    xi_folds <- matrix(NA, nrow=dimX+1, ncol=K)
    #B_boo_folds <- array(NA, dim = c(dimS, NBoot, K))
    #C_boo_folds <- array(NA, dim = c(dimS, dimS, NBoot, K))
    #D_boo_folds <- array(NA, dim = c(NBoot, K))
    
    for (j in 1:K){
      
      idNj = (Index!=j) # for training, (1-1/K)*n dp
      idj = (Index==j) # for estimation, (1/K)*n dp
      
      # training set
      In <- lapply(DP, function(component) {
        if (is.matrix(component)) {
          component[idNj, , drop = FALSE]
        } else {
          component[idNj]
        }})

      # estimation set
      Out <- lapply(DP, function(component) {
        if (is.matrix(component)) {
          component[idj, , drop = FALSE]
        } else {
          component[idj]
        }})
      
      # target set
      Target <- DP$Xt
      
      # estimation
      result_j <- tryCatch(
        estimate(In, Out, Target, givenestimator, NBoot),
        error = function(e) {
          list(
            NuisanceFit = list(),
            TargetFit = list()
            # se_theta= rep(NaN, dimS),
            # se_tau  = NaN
          )
        }
      )
      
      # point estimate:
      NuisanceFit_folds[[j]]  <- result_j$NuisanceFit
      TargetFit_folds[[j]]    <- result_j$TargetFit
      
    }
    
    ###----------------------------------------- Iteration -----------------------------------------###
    tol        <- 0.1 # adjust later
    max_iter   <- 100
    prev_avg_V <- Inf
    gamma      <- gamma0 
    
    for (iter in 1:max_iter) {
    
    # P, Q:
    for (j in 1:K) {
      P_hat_folds[,,j]  <- calculation_pq(NuisanceFit_folds[[j]], TargetFit_folds[[j]], gamma)$P # can also move out
      Q_hat_folds[,j]   <- calculation_pq(NuisanceFit_folds[[j]], TargetFit_folds[[j]], gamma)$Q
    }

    # Beta: (average P, Q over folds)
    avg_P    <- apply(P_hat_folds, c(1, 2), mean, na.rm = TRUE)
    avg_Q    <- rowMeans(Q_hat_folds, na.rm = TRUE)
    beta_opt <- solve(avg_P) %*% avg_Q
    
    # V, ha, xi:
    for (j in 1:K){
      V[j] <- Vab(NuisanceFit_folds[[j]], TargetFit_folds[[j]])
      ha_folds[,,j] <- new_gamma(NuisanceFit_folds[[j]], TargetFit_folds[[j]], gamma, beta_opt)$ha
      xi_folds[,j]  <- new_gamma(NuisanceFit_folds[[j]], TargetFit_folds[[j]], gamma, beta_opt)$xi
    }
    
    avg_V <- mean(V) # evaluate the convergence of avg_V
    avg_ha   <- apply(ha_folds, c(1, 2), mean, na.rm = TRUE)
    avg_xi   <- rowMeans(xi_folds, na.rm = TRUE)
    gamma_new <- gamma - solve(avg_ha) %*% avg_xi
    
    cat(sprintf("iter %d : avg_V = %.5f  |Î”V| = %.5f\n",
              iter, avg_V, abs(avg_V - prev_avg_V)))
    
    
    if (abs(avg_V - prev_avg_V) < tol) {
      message("Converged!")
      break
    }
    
    ## update for next iteration
    prev_avg_V <- avg_V
    gamma      <- gamma_new
  }
    

    ## bootstrapped theta and tau calculation through B, C, D
    #theta_boo <- matrix(NA, nrow=dimS, ncol=NBoot)  # each col is theta_boo_r
    #tau_boo   <- numeric(NBoot)
    
    #for (r in seq_len(NBoot)) {
    ## gather across j=1..K
    #B_r_j <- B_boo_folds[, r, ]       # dimS x K
    #C_r_j <- C_boo_folds[,, r, ]      # dimS x dimS x K
    #D_r_j <- D_boo_folds[r, ]         # length K
    #
    ## average bridging terms
    #B_r <- rowMeans(B_r_j, na.rm=TRUE)
    #C_r <- apply(C_r_j, c(1, 2), mean, na.rm=TRUE)
    #D_r <- mean(D_r_j, na.rm=TRUE)
    #
    ## compute theta_boo_r, tau_boo_r
    #theta_boo[, r] <- solve(C_r) %*% B_r
    #tau_boo[r]     <- as.numeric(t(B_r) %*% solve(C_r) %*% B_r) / D_r
    #}
    
    ##ADD#: se
    #se_theta <- apply(theta_boo, 1, sd, na.rm=TRUE)  # length dimS
    #se_tau   <- sd(tau_boo, na.rm=TRUE)
    #
    ##ADD#: 95% lower+upper bound
    #theta_ci <- apply(theta_boo, 1, quantile, probs = c(0.025, 0.975), na.rm = TRUE)
    #tau_ci   <- quantile(tau_boo, probs = c(0.025, 0.975), na.rm = TRUE)
    
    # Store results for this simulation
    #theta_hat_list[[i]]   <- theta_hat
    #tau_hat_list[[i]]     <- tau_hat
    #se_theta_list[[i]]    <- se_theta
    #se_tau_list[[i]]      <- se_tau
    #theta_ci_lower_list[[i]] <- theta_ci[1,]  # Lower bound for each dimension of theta
    #theta_ci_upper_list[[i]] <- theta_ci[2,]  # Upper bound for each dimension of theta
    #tau_ci_lower_list[[i]]   <- tau_ci[1]     # Lower bound for tau
    #tau_ci_upper_list[[i]]   <- tau_ci[2]     # Upper bound for tau
    
  }
  #return(list(theta_hat = theta_hat_list, 
  #            tau_hat = tau_hat_list, 
  #            theta_se = se_theta_list, 
  #            tau_se = se_tau_list,
  #            theta_ci_lower = theta_ci_lower_list,
  #            theta_ci_upper = theta_ci_upper_list,
  #            tau_ci_lower = tau_ci_lower_list,
  #            tau_ci_upper = tau_ci_upper_list
  #            ))
}
```


# Simulation Conducting
```{r}
t5rf = sim_function(N=1, n=1000, K=5, 'svmLinear2', NBoot)
```

```{r}
N <- 100
K <- 5
sample_sizes <- c(1000)
NBoot <- 100
```

```{r}
givenestimator <- 'nnet'
results_by_n <- list()

for (n in sample_sizes) {
  
  results_by_n[[as.character(n)]] <- data.frame()
  
  for (i in 1:N) {
    set.seed(200427 + i)
    # N=1 inside sim_function so that each call returns one replication
    sim_results <- sim_function(1, n, K = 5, givenestimator, NBoot) #!# ml estimation for nuisance
    
    # sim_results$theta[[1]] is a vector of length 2
    theta_vec <- as.vector(sim_results$theta_hat[[1]])
    tau   <- sim_results$tau_hat[[1]]
    theta_se_vec <- as.vector(sim_results$theta_se[[1]])
    tau_se   <- sim_results$tau_se[[1]]
    theta_lower_vec <- as.vector(sim_results$theta_ci_lower[[1]])
    theta_upper_vec <- as.vector(sim_results$theta_ci_upper[[1]])
    tau_lower   <- sim_results$tau_ci_lower[[1]]
    tau_upper   <- sim_results$tau_ci_upper[[1]]
    
    temp <- data.frame(
      replicate = i,
      theta1 = theta_vec[1],
      theta2 = theta_vec[2],
      tau = tau,
      theta1_se  = theta_se_vec[1],
      theta2_se  = theta_se_vec[2],
      tau_se     = tau_se,
      theta1_low = theta_lower_vec[1],
      theta1_up  = theta_upper_vec[1],
      theta2_low = theta_lower_vec[2],
      theta2_up  = theta_upper_vec[2],
      tau_low    = tau_lower,
      tau_up     = tau_upper
    )
    
    # append the result for this replication
    results_by_n[[as.character(n)]] <- rbind(results_by_n[[as.character(n)]], temp)
    
    csv_filename <- paste0(
      givenestimator, "_",        
      n, "_",                    
      Sys.Date(),                
      ".csv"
    )
    
    write.csv(results_by_n[[as.character(n)]], # save csv after each loop
              file = file.path("./output", csv_filename), 
              row.names = FALSE)
  }
}

```

```{r}
calc_metrics <- function(df, true_theta1, true_theta2, true_tau) {
  
  # For theta1
  bias_theta1 <- mean(df$theta1 - true_theta1, na.rm = TRUE)
  ese_theta1  <- sd(df$theta1, na.rm = TRUE) # empirical se
  ase_theta1  <- mean(df$theta1_se, na.rm = TRUE) # average se
  # coverage prob:
  lower_theta1_0 <- df$theta1 - qnorm(0.975) * ese_theta1 # using ese
  upper_theta1_0 <- df$theta1 + qnorm(0.975) * ese_theta1
  lower_theta1 <- df$theta1 - qnorm(0.975) * df$theta1_se # using ase
  upper_theta1 <- df$theta1 + qnorm(0.975) * df$theta1_se
  coverage_theta1_0 <- mean(lower_theta1_0 <= true_theta1 & true_theta1 <= upper_theta1_0, na.rm = TRUE)
  coverage_theta1 <- mean(lower_theta1 <= true_theta1 & true_theta1 <= upper_theta1, na.rm = TRUE)
  coverage_theta1_2 <- mean(df$theta1_low <= true_theta1 & true_theta1 <= df$theta1_up, na.rm = TRUE) # quantile
  
  # For theta2
  bias_theta2 <- mean(df$theta2 - true_theta2, na.rm = TRUE)
  ese_theta2  <- sd(df$theta2, na.rm = TRUE)
  ase_theta2  <- mean(df$theta2_se, na.rm = TRUE)
  # coverage prob:
  lower_theta2_0 <- df$theta2 - qnorm(0.975) * ese_theta2 # using ese
  upper_theta2_0 <- df$theta2 + qnorm(0.975) * ese_theta2
  lower_theta2 <- df$theta2 - qnorm(0.975) * df$theta2_se # using ase
  upper_theta2 <- df$theta2 + qnorm(0.975) * df$theta2_se
  coverage_theta2_0 <- mean(lower_theta2_0 <= true_theta2 & true_theta2 <= upper_theta2_0, na.rm = TRUE)
  coverage_theta2 <- mean(lower_theta2 <= true_theta2 & true_theta2 <= upper_theta2, na.rm = TRUE)
  coverage_theta2_2 <- mean(df$theta2_low <= true_theta2 & true_theta2 <= df$theta2_up, na.rm = TRUE) # quantile
  
  # For tau
  bias_tau <- mean(df$tau - true_tau, na.rm = TRUE)
  ese_tau  <- sd(df$tau, na.rm = TRUE)
  ase_tau  <- mean(df$tau_se, na.rm = TRUE)
    # coverage prob:
  lower_tau_0 <- df$tau - qnorm(0.975) * ese_tau # using ese
  upper_tau_0 <- df$tau + qnorm(0.975) * ese_tau
  lower_tau <- df$tau - qnorm(0.975) * df$tau_se # using ase
  upper_tau <- df$tau + qnorm(0.975) * df$tau_se
  coverage_tau_0 <- mean(lower_tau_0 <= true_tau & true_tau <= upper_tau_0, na.rm = TRUE)
  coverage_tau <- mean(lower_tau <= true_tau & true_tau <= upper_tau, na.rm = TRUE)
  coverage_tau_2 <- mean(df$tau_low <= true_tau & true_tau <= df$tau_up, na.rm = TRUE) # quantile
  
  result <- rbind(
    data.frame(variable = "Theta1", true_value = true_theta1, bias = bias_theta1, ese = ese_theta1, ase = ase_theta1, coverage0 = coverage_theta1_0, coverage = coverage_theta1, coverage2 = coverage_theta1_2),
    data.frame(variable = "Theta2", true_value = true_theta2, bias = bias_theta2, ese = ese_theta2, ase = ase_theta2, coverage0 = coverage_theta2_0, coverage = coverage_theta2, coverage2 = coverage_theta2_2),
    data.frame(variable = "Tau", true_value = true_tau,    bias = bias_tau,  ese = ese_tau,  ase = ase_tau,  coverage0 = coverage_tau_0, coverage = coverage_tau, coverage2 = coverage_tau_2)
  )
  
  return(result)
}
```

```{r}
#result = read.csv("./output/nnet_1000_2025-04-04.csv")
result = results_by_n$`1000`
result_sum <- calc_metrics(result[-c(78, 40, 5),], theta_true13[[1]], theta_true13[[2]], tau_t13)
result_sum
```

```{r}
result = read.csv("./som_output/svmLinear2_1000_2025-03-20.csv")
result_sum <- calc_metrics(result[-c(46, 77),], theta_true10[[1]], theta_true10[[2]], tau_t10)
result_sum
```


